{"cells":[{"cell_type":"markdown","metadata":{},"source":["## 0. Data downloading"]},{"cell_type":"code","execution_count":3,"id":"48f8f6d1","metadata":{"execution":{"iopub.execute_input":"2024-08-03T21:32:17.040856Z","iopub.status.busy":"2024-08-03T21:32:17.040461Z","iopub.status.idle":"2024-08-03T21:32:17.046370Z","shell.execute_reply":"2024-08-03T21:32:17.045544Z","shell.execute_reply.started":"2024-08-03T21:32:17.040826Z"},"trusted":true},"outputs":[],"source":["import json\n","# set api key\n","api_token = {\"username\":\"dd13969\",\"key\":\"\"}\n","with open('/root/.kaggle/kaggle.json', 'w') as file:\n","    json.dump(api_token, file)"]},{"cell_type":"code","execution_count":4,"id":"8732dd81","metadata":{"execution":{"iopub.execute_input":"2024-08-03T21:32:23.994183Z","iopub.status.busy":"2024-08-03T21:32:23.993832Z","iopub.status.idle":"2024-08-03T21:32:28.041926Z","shell.execute_reply":"2024-08-03T21:32:28.040767Z","shell.execute_reply.started":"2024-08-03T21:32:23.994152Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n","Downloading nzmsa-2024.zip to /kaggle/working\n"," 87%|██████████████████████████████████▊     | 113M/130M [00:01<00:00, 76.3MB/s]\n","100%|████████████████████████████████████████| 130M/130M [00:01<00:00, 75.2MB/s]\n"]}],"source":["!kaggle competitions download -c nzmsa-2024"]},{"cell_type":"code","execution_count":5,"id":"d6c4ed4c","metadata":{"execution":{"iopub.execute_input":"2024-08-03T21:32:30.543329Z","iopub.status.busy":"2024-08-03T21:32:30.542959Z","iopub.status.idle":"2024-08-03T21:32:36.907695Z","shell.execute_reply":"2024-08-03T21:32:36.906694Z","shell.execute_reply.started":"2024-08-03T21:32:30.543297Z"},"trusted":true},"outputs":[],"source":["import os\n","import zipfile\n","\n","# unzip dataset\n","def unzipDataset(data_dir):\n","    zip_path = data_dir + '.zip'\n","    extract_path = os.getcwd()\n","\n","    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n","        zip_ref.extractall(extract_path)\n","file_name = 'nzmsa-2024'\n","unzipDataset(file_name)"]},{"cell_type":"markdown","id":"c5667353","metadata":{},"source":["## 1. Data loading & preprocessing\n","\n","Try following data preprocessing and augmentation:\n","- RandomResizedCrop: useful\n","- RandomHorizontalFlip: useful\n","- RandomRotation: negtive effects\n","- RandomVerticalFlip: negtive effects\n","- Normalize: unuseful"]},{"cell_type":"code","execution_count":11,"id":"b30a4f53","metadata":{"execution":{"iopub.execute_input":"2024-08-04T08:33:05.557083Z","iopub.status.busy":"2024-08-04T08:33:05.556700Z","iopub.status.idle":"2024-08-04T08:33:05.972066Z","shell.execute_reply":"2024-08-04T08:33:05.971086Z","shell.execute_reply.started":"2024-08-04T08:33:05.557053Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["train dataset size: 40000, validation dataset size: 10000, test datasetsize: 5000\n"]}],"source":["import csv\n","import os\n","from PIL import Image\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms\n","from sklearn.model_selection import train_test_split\n","\n","# data preprocessing and augmentation\n","train_transforms = transforms.Compose([\n","    transforms.RandomResizedCrop((32,32)),\n","#     transforms.RandomRotation(180),\n","    transforms.RandomHorizontalFlip(p=0.5),\n","#     transforms.RandomVerticalFlip(p=0.1),\n","    transforms.ToTensor(),\n","    # transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n","])\n","\n","val_transforms = transforms.Compose([\n","    transforms.ToTensor(),\n","])\n","\n","test_transforms = transforms.Compose([\n","    transforms.ToTensor(),\n","])\n","\n","\n","# define dataset\n","class CIFAR10Dataset(Dataset):\n","    \"\"\"`CIFAR10 Dataset.\n","\n","    Args:\n","        data_list (list[str]): The images files paths of the CIFAR10 Dataset.\n","        label_path (str): The path of label file.\n","        transform (callable, optional): A function/transform that takes in a PIL image and returns a transformed version.\n","    \"\"\"\n","    def __init__(self, data_list, label_path, transform=None):\n","        self.data_list = data_list\n","        self.label_dict = self._csv2dict(label_path)\n","        self.transform = transform\n","        if self.transform is None:\n","            self.transform = transforms.ToTensor()\n","\n","    def _csv2dict(self, label_path):\n","        \"\"\"Load labels from csv file\"\"\"\n","        label_dict = {}\n","        with open(label_path, mode='r', encoding='utf-8') as csv_file:\n","            reader = csv.DictReader(csv_file)\n","            for row in reader:\n","                label_dict[f'image_{row[\"id\"]}.png'] = int(row['label']) \n","        return label_dict\n","\n","    def __len__(self):\n","        return len(self.data_list)\n","     \n","    def __getitem__(self, idx):\n","        img_path = self.data_list[idx]\n","        img = Image.open(img_path)\n","        img = img.convert(\"RGB\")\n","        img_transformed = self.transform(img)\n","        label = self.label_dict[img_path.split('/')[-1]]\n","        return img_transformed, label\n","\n","class TestDataset(CIFAR10Dataset):\n","    \"\"\"`CIFAR10 test Dataset.\n","\n","    Args:\n","        data_list (list[str]): The images files paths of the CIFAR10 Dataset.\n","        transform (callable, optional): A function/transform that takes in a PIL image and returns a transformed version.\n","    \"\"\"\n","    def __init__(self, data_list, transform=None):\n","        self.data_list = data_list\n","        self.transform = transform\n","        if self.transform is None:\n","            self.transform = transforms.ToTensor()\n","\n","    def __getitem__(self, idx):\n","        img_path = self.data_list[idx]\n","        img = Image.open(img_path)\n","        img = img.convert(\"RGB\")\n","        img_transformed = self.transform(img)\n","        id = img_path.split('_')[-1][:-4]\n","        return img_transformed, id\n","\n","\n","# dataset root\n","data_root = 'cifar10_images/train'\n","test_data_root = 'cifar10_images/test'\n","label_path = 'train.csv'\n","\n","# read data path list\n","data_list = ['/'.join([data_root, i]) for i in os.listdir(data_root)]\n","test_list = ['/'.join([test_data_root, i]) for i in os.listdir(test_data_root)]\n","train_list, val_list = train_test_split(data_list, test_size=0.2,random_state=101)\n","print(f'train dataset size: {len(train_list)}, validation dataset size: {len(val_list)}, test datasetsize: {len(test_list)}')\n","\n","# build train, validation and test dataset\n","train_dataset = CIFAR10Dataset(train_list, label_path, train_transforms)\n","val_dataset = CIFAR10Dataset(val_list, label_path, val_transforms)\n","test_dataset = TestDataset(test_list, test_transforms)"]},{"cell_type":"markdown","id":"c458bc00","metadata":{},"source":["## 2. Define the model"]},{"cell_type":"markdown","id":"04c7e03f","metadata":{},"source":["### Resnet\n","- Classic CNN network.\n","- Very easy to achieve 90%+ score on this dataset."]},{"cell_type":"code","execution_count":12,"id":"3a1f83ce","metadata":{"execution":{"iopub.execute_input":"2024-08-03T21:33:09.291265Z","iopub.status.busy":"2024-08-03T21:33:09.290620Z","iopub.status.idle":"2024-08-03T21:33:09.316432Z","shell.execute_reply":"2024-08-03T21:33:09.315460Z","shell.execute_reply.started":"2024-08-03T21:33:09.291230Z"},"trusted":true},"outputs":[],"source":["import torch.nn as nn\n","\n","class BasicBlock(nn.Module):\n","    \"\"\"Basic Block for Resnet18 and Resnet34.\n","\n","    Args:\n","        in_channels (int): Number of input channels.\n","        out_channels (int): Number of output channels.\n","        stride (int): Stride of the first conv module, default to 1.\n","    \"\"\"\n","\n","    expansion = 1 # distinct BasicBlock and BottleNeck\n","\n","    def __init__(self,\n","                 in_channels: int,\n","                 out_channels: int,\n","                 stride: int = 1):\n","        super().__init__()\n","\n","        # residual function\n","        self.residual_function = nn.Sequential(\n","            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False),\n","            nn.BatchNorm2d(out_channels),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(out_channels, out_channels * BasicBlock.expansion, kernel_size=3, padding=1, bias=False),\n","            nn.BatchNorm2d(out_channels * BasicBlock.expansion)\n","        )\n","\n","        # shortcut\n","        self.shortcut = nn.Sequential()\n","        # when output dimension != input dimension\n","        if stride != 1 or in_channels != BasicBlock.expansion * out_channels:\n","            self.shortcut = nn.Sequential(\n","                nn.Conv2d(in_channels, out_channels * BasicBlock.expansion, kernel_size=1, stride=stride, bias=False),\n","                nn.BatchNorm2d(out_channels * BasicBlock.expansion)\n","            )\n","\n","    def forward(self, x):\n","        output = self.residual_function(x)\n","        output += self.shortcut(x)\n","        return nn.ReLU(inplace=True)(output)\n","\n","\n","class BottleNeck(nn.Module):\n","    \"\"\"Residual block for resnet over 50 layers.\n","\n","    Args:\n","        in_channels (int): Number of input channels.\n","        out_channels (int): Number of output channels.\n","        stride (int): Stride of the first conv module, default to 1.\n","    \"\"\"\n","\n","    expansion = 4 # distinct BasicBlock and BottleNeck\n","\n","    def __init__(self,\n","                 in_channels: int,\n","                 out_channels: int,\n","                 stride: int = 1):\n","        super().__init__()\n","\n","        # residual function\n","        self.residual_function = nn.Sequential(\n","            nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False),\n","            nn.BatchNorm2d(out_channels),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(out_channels, out_channels, stride=stride, kernel_size=3, padding=1, bias=False),\n","            nn.BatchNorm2d(out_channels),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(out_channels, out_channels * BottleNeck.expansion, kernel_size=1, bias=False),\n","            nn.BatchNorm2d(out_channels * BottleNeck.expansion),\n","        )\n","\n","        # shortcut\n","        self.shortcut = nn.Sequential()\n","        # when output dimension != input dimension\n","        if stride != 1 or in_channels != out_channels * BottleNeck.expansion:\n","            self.shortcut = nn.Sequential(\n","                nn.Conv2d(in_channels, out_channels * BottleNeck.expansion, stride=stride, kernel_size=1, bias=False),\n","                nn.BatchNorm2d(out_channels * BottleNeck.expansion)\n","            )\n","\n","    def forward(self, x):\n","        output = self.residual_function(x)\n","        output += self.shortcut(x)\n","        return nn.ReLU(inplace=True)(output)\n","\n","\n","class ResNet(nn.Module):\n","    \"\"\"General ResNet.\n","\n","    Args:\n","        block (str): Type of residul block\n","        num_block (list[int]): Depth of every stage.\n","        num_classes (int): Determine the output dimension, default to 10.\n","    \"\"\"\n","\n","    def __init__(self,\n","                 block: str,\n","                 num_block: list,\n","                 num_classes: int = 10):\n","        super().__init__()\n","\n","        self.in_channels = 64\n","\n","        self.conv1 = nn.Sequential(\n","            nn.Conv2d(3, 64, kernel_size=3, padding=1, bias=False),\n","            nn.BatchNorm2d(64),\n","            nn.ReLU(inplace=True))\n","        self.layer1 = self._make_layer(block, 64, num_block[0], 1)\n","        self.layer2 = self._make_layer(block, 128, num_block[1], 2)\n","        self.layer3 = self._make_layer(block, 256, num_block[2], 2)\n","        self.layer4 = self._make_layer(block, 512, num_block[3], 2)\n","        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n","        self.fc = nn.Linear(512 * block.expansion, num_classes)\n","\n","    def _make_layer(self, block, out_channels, num_blocks, stride):\n","        strides = [stride] + [1] * (num_blocks - 1)\n","        layers = []\n","        for stride in strides:\n","            layers.append(block(self.in_channels, out_channels, stride))\n","            self.in_channels = out_channels * block.expansion\n","\n","        return nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        output = self.conv1(x)\n","        output = self.layer1(output)\n","        output = self.layer2(output)\n","        output = self.layer3(output)\n","        output = self.layer4(output)\n","        output = self.avg_pool(output)\n","        output = output.view(output.size(0), -1)\n","        output = self.fc(output)\n","\n","        return output\n","\n","# different scale of ResNet\n","def resnet18():\n","    return ResNet(BasicBlock, [2, 2, 2, 2])\n","\n","def resnet34():\n","    return ResNet(BasicBlock, [3, 4, 6, 3])\n","\n","def resnet50():\n","    return ResNet(BottleNeck, [3, 4, 6, 3])\n","\n","def resnet101():\n","    return ResNet(BottleNeck, [3, 4, 23, 3])\n","\n","def resnet152():\n","    return ResNet(BottleNeck, [3, 8, 36, 3])"]},{"cell_type":"markdown","id":"c1847a76","metadata":{},"source":["### ViT\n","- Use transformer framework on vision tasks\n","- Training more slowly than ResNet\n","- Hard to tune hyper-parameters\n","- Because not allowed to use extra dataset and pre-trained model, it's hard to achieve high performance."]},{"cell_type":"code","execution_count":13,"id":"a500b8ad","metadata":{"execution":{"iopub.execute_input":"2024-08-03T21:34:21.126069Z","iopub.status.busy":"2024-08-03T21:34:21.125723Z","iopub.status.idle":"2024-08-03T21:34:21.160436Z","shell.execute_reply":"2024-08-03T21:34:21.159606Z","shell.execute_reply.started":"2024-08-03T21:34:21.126040Z"},"trusted":true},"outputs":[],"source":["import torch\n","from torch import nn\n","from einops import rearrange, repeat\n","from einops.layers.torch import Rearrange\n","\n","\"\"\"\"\n","Reference: https://github.com/lucidrains/vit-pytorch\n","\"\"\"\n","\n","def pair(t):\n","    return t if isinstance(t, tuple) else (t, t)\n","\n","class FeedForward(nn.Module):\n","    def __init__(self, dim, hidden_dim, dropout = 0.):\n","        super().__init__()\n","        self.net = nn.Sequential(\n","            nn.LayerNorm(dim),\n","            nn.Linear(dim, hidden_dim),\n","            nn.GELU(),\n","            nn.Dropout(dropout),\n","            nn.Linear(hidden_dim, dim),\n","            nn.Dropout(dropout)\n","        )\n","\n","    def forward(self, x):\n","        return self.net(x)\n","\n","class Attention(nn.Module):\n","    def __init__(self, dim, heads = 8, dim_head = 64, dropout = 0.):\n","        super().__init__()\n","        inner_dim = dim_head *  heads\n","        project_out = not (heads == 1 and dim_head == dim)\n","\n","        self.heads = heads\n","        self.scale = dim_head ** -0.5\n","\n","        self.norm = nn.LayerNorm(dim)\n","\n","        self.attend = nn.Softmax(dim = -1)\n","        self.dropout = nn.Dropout(dropout)\n","\n","        self.to_qkv = nn.Linear(dim, inner_dim * 3, bias = False)\n","\n","        self.to_out = nn.Sequential(\n","            nn.Linear(inner_dim, dim),\n","            nn.Dropout(dropout)\n","        ) if project_out else nn.Identity()\n","\n","    def forward(self, x):\n","        x = self.norm(x)\n","\n","        qkv = self.to_qkv(x).chunk(3, dim = -1)\n","        q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> b h n d', h = self.heads), qkv)\n","\n","        dots = torch.matmul(q, k.transpose(-1, -2)) * self.scale\n","\n","        attn = self.attend(dots)\n","        attn = self.dropout(attn)\n","\n","        out = torch.matmul(attn, v)\n","        out = rearrange(out, 'b h n d -> b n (h d)')\n","        return self.to_out(out)\n","\n","class Transformer(nn.Module):\n","    def __init__(self, dim, depth, heads, dim_head, mlp_dim, dropout = 0.):\n","        super().__init__()\n","        self.norm = nn.LayerNorm(dim)\n","        self.layers = nn.ModuleList([])\n","        for _ in range(depth):\n","            self.layers.append(nn.ModuleList([\n","                Attention(dim, heads = heads, dim_head = dim_head, dropout = dropout),\n","                FeedForward(dim, mlp_dim, dropout = dropout)\n","            ]))\n","\n","    def forward(self, x):\n","        for attn, ff in self.layers:\n","            x = attn(x) + x\n","            x = ff(x) + x\n","\n","        return self.norm(x)\n","\n","class ViT(nn.Module):\n","    def __init__(self, *, image_size, patch_size, num_classes, dim, depth, heads, mlp_dim, pool = 'cls', channels = 3, dim_head = 64, dropout = 0., emb_dropout = 0.):\n","        super().__init__()\n","        image_height, image_width = pair(image_size)\n","        patch_height, patch_width = pair(patch_size)\n","\n","        assert image_height % patch_height == 0 and image_width % patch_width == 0, 'Image dimensions must be divisible by the patch size.'\n","\n","        num_patches = (image_height // patch_height) * (image_width // patch_width)\n","        patch_dim = channels * patch_height * patch_width\n","        assert pool in {'cls', 'mean'}, 'pool type must be either cls (cls token) or mean (mean pooling)'\n","\n","        self.to_patch_embedding = nn.Sequential(\n","            Rearrange('b c (h p1) (w p2) -> b (h w) (p1 p2 c)', p1 = patch_height, p2 = patch_width),\n","            nn.LayerNorm(patch_dim),\n","            nn.Linear(patch_dim, dim),\n","            nn.LayerNorm(dim),\n","        )\n","\n","        self.pos_embedding = nn.Parameter(torch.randn(1, num_patches + 1, dim))\n","        self.cls_token = nn.Parameter(torch.randn(1, 1, dim))\n","        self.dropout = nn.Dropout(emb_dropout)\n","\n","        self.transformer = Transformer(dim, depth, heads, dim_head, mlp_dim, dropout)\n","\n","        self.pool = pool\n","        self.to_latent = nn.Identity()\n","\n","        self.mlp_head = nn.Linear(dim, num_classes)\n","\n","    def forward(self, img):\n","        x = self.to_patch_embedding(img)\n","        b, n, _ = x.shape\n","\n","        cls_tokens = repeat(self.cls_token, '1 1 d -> b 1 d', b = b)\n","        x = torch.cat((cls_tokens, x), dim=1)\n","        x += self.pos_embedding[:, :(n + 1)]\n","        x = self.dropout(x)\n","\n","        x = self.transformer(x)\n","\n","        x = x.mean(dim = 1) if self.pool == 'mean' else x[:, 0]\n","\n","        x = self.to_latent(x)\n","        return self.mlp_head(x)"]},{"cell_type":"markdown","id":"6ed5f8a3","metadata":{},"source":["## 3. Train & Test pipeline\n","\n","Unified pipelines to train model and test on test dataset."]},{"cell_type":"markdown","id":"2ad6dfc2","metadata":{},"source":["### train pipeline"]},{"cell_type":"code","execution_count":14,"id":"5626886d","metadata":{"execution":{"iopub.execute_input":"2024-08-04T08:31:32.990561Z","iopub.status.busy":"2024-08-04T08:31:32.989687Z","iopub.status.idle":"2024-08-04T08:31:33.010926Z","shell.execute_reply":"2024-08-04T08:31:33.009806Z","shell.execute_reply.started":"2024-08-04T08:31:32.990527Z"},"trusted":true},"outputs":[],"source":["import os\n","import time\n","import torch\n","def train(model,\n","          train_dataset,\n","          val_dataset,\n","          batch_size,\n","          epoch,\n","          loss_function,\n","          optimizer,\n","          output_root = './outputs',\n","          save_epoch = 1,\n","          resume = None,\n","          start_epoch = 1,\n","          device = 'cuda:0'\n","    ):\n","\n","    model = model.to(device)\n","\n","    # resume\n","    if resume:\n","        model.load_state_dict(torch.load(resume))\n","        model.to(device)\n","\n","    # make save path\n","    current_time = time.strftime('%Y_%m_%d_%H_%M_%S', time.localtime())\n","    output_path = os.path.join(output_root, current_time)\n","    os.makedirs(output_path, exist_ok=True)\n","\n","    # build dataloader\n","    train_dataloader = DataLoader(dataset = train_dataset, batch_size=batch_size, shuffle=True )\n","    val_dataloader = DataLoader(dataset = val_dataset, batch_size=batch_size, shuffle=True)\n","\n","    # used for logging\n","    iter_num =  int(len(train_dataset) / train_dataloader.batch_size)\n","    best_acc = 0\n","    f_log = open(os.path.join(output_path, 'log.log'), 'w', encoding='utf-8')\n","    f_loss_acc = open(os.path.join(output_path, 'loss.log'), 'w', encoding='utf-8')\n","\n","    for e in range(start_epoch, epoch+1):\n","        train_loss = 0\n","        train_accuracy = 0\n","        \n","        for idx, (data, label) in enumerate(train_dataloader):\n","            data, label = data.to(device), label.to(device)\n","\n","            outputs = model(data)\n","            loss = loss_function(outputs, label)\n","\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","\n","            # compute accurency and loss\n","            acc = (outputs.argmax(dim=1) == label).float().mean()\n","            train_accuracy += acc / len(train_dataloader)\n","            train_loss += loss / len(train_dataloader)\n","\n","            # logging\n","            if idx % 100 == 0:\n","                print(f'Epoch:{e}/{epoch}, iter:{idx}/{iter_num}, loss:{loss.item():.4f}')\n","                f_log.write(f'Epoch:{e}/{epoch}, iter:{idx}/{iter_num}, loss:{loss.item():.4f}\\n')\n","\n","            f_loss_acc.write(f'{loss.item():.4f}\\n')\n","\n","        # validation of each epoch\n","        label_list = []\n","        prediction_list = []\n","        with torch.no_grad():\n","            val_accuracy = 0\n","            val_loss = 0\n","            for idx, (data, label) in enumerate(val_dataloader):\n","                data = data.to(device)\n","                label = label.to(device)\n","\n","                outputs = model(data)\n","                loss = loss_function(outputs, label)\n","                acc = (outputs.argmax(dim=1) == label).float().mean()\n","                val_accuracy += acc / len(val_dataloader)\n","                val_loss += loss / len(val_dataloader)\n","\n","                label_list += label.tolist()\n","                prediction_list += outputs.argmax(dim=1).tolist()\n","\n","        print(f'Epoch:{e}/{epoch}, train_loss:{train_loss:.4f}, train_accuracy:{train_accuracy:.4f}, val_loss:{val_loss:.4f}, val_accuracy:{val_accuracy:.4f}')\n","        f_log.write(f'Epoch:{e}/{epoch}, train_loss:{train_loss:.4f}, train_accuracy:{train_accuracy:.4f}, val_loss:{val_loss:.4f}, val_accuracy:{val_accuracy:.4f}\\n')\n","        \n","        # model saving\n","        if best_acc < val_accuracy:\n","            model_name = f'best_epoch_{e}_{val_accuracy:.4f}.pth'\n","            save_path = os.path.join(output_path, model_name)\n","            print(f'saving best model to {save_path}')\n","            torch.save(model.state_dict(), save_path)\n","            best_acc = val_accuracy\n","            continue\n","\n","        if epoch % save_epoch == 0:\n","            model_name = f'epoch_{e}_{val_accuracy:.4f}.pth'\n","            save_path = os.path.join(output_path, model_name)\n","            print(f'saving model to {save_path}')\n","            torch.save(model.state_dict(), save_path)\n","    \n","    \n","    f_loss_acc.close()\n","    f_log.close()\n"]},{"cell_type":"markdown","id":"9471b666","metadata":{},"source":["### test pipeline"]},{"cell_type":"code","execution_count":15,"id":"92168ee9","metadata":{"execution":{"iopub.execute_input":"2024-08-03T21:34:37.505370Z","iopub.status.busy":"2024-08-03T21:34:37.504696Z","iopub.status.idle":"2024-08-03T21:34:37.513211Z","shell.execute_reply":"2024-08-03T21:34:37.512301Z","shell.execute_reply.started":"2024-08-03T21:34:37.505338Z"},"trusted":true},"outputs":[],"source":["def test(model,\n","         checkpoint_path,\n","         test_dataset,\n","         batch_size,\n","         result_path = 'submission.csv',\n","         device = 'cuda:0',\n","    ):\n","\n","    model.load_state_dict(torch.load(checkpoint_path))\n","    model.to(device)\n","    test_dataloader = DataLoader(dataset = test_dataset, batch_size=batch_size)\n","    \n","    current_time = time.strftime('%Y_%m_%d_%H_%M_%S', time.localtime())\n","    output_path = os.path.join('./submissions', current_time)\n","    os.makedirs(output_path, exist_ok=True)\n","    f = open(os.path.join(output_path, result_path), 'w', encoding='utf-8')\n","    f.write('id,label\\n')\n","\n","    with torch.no_grad():\n","        for data, ids in test_dataloader:\n","            data = data.to(device)\n","\n","            outputs = model(data)\n","            labels = outputs.argmax(dim=1)\n","            for i in range(len(ids)):\n","                f.write(f'{ids[i]},{labels[i]}\\n')\n","    f.close()"]},{"cell_type":"markdown","id":"ef5b4dc4","metadata":{},"source":["## 4. Train model"]},{"cell_type":"markdown","id":"3a66001d","metadata":{},"source":["### Train ResNet"]},{"cell_type":"code","execution_count":null,"id":"0275feac","metadata":{},"outputs":[],"source":["from torch.optim.lr_scheduler import StepLR, MultiStepLR, CosineAnnealingLR\n","import torch.optim as optim\n","\n","# build models\n","# model = resnet18()\n","model = resnet34()\n","# model = resnet50()\n","# model = resnet101()\n","# model = resnet152()\n","\n","# loss function\n","loss_function = nn.CrossEntropyLoss()\n","\n","# select optimizer\n","lr = 1e-4\n","momnetum = 0.9\n","weught_decay = 0.0001\n","optimizer = optim.Adam(model.parameters(), lr=lr)\n","# optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momnetum, weight_decay=weught_decay)\n","\n","# scheduler\n","gamma = 0.1\n","scheduler = StepLR(optimizer, step_size=1, gamma=gamma)\n","# scheduler = MultiStepLR(optimizer, milestones=[100, 150], gamma=0.1)\n","# secheduler = CosineAnnealingLR(optimizer, T_max=100, eta_min=1e-5)\n","\n","train(model=model,\n","      train_dataset=train_dataset,\n","      val_dataset=val_dataset,\n","      epoch=100,\n","      batch_size=32,\n","      loss_function=loss_function,\n","      optimizer=optimizer,\n","#       resume='',\n","#       start_epoch=21,\n",")"]},{"cell_type":"markdown","id":"eb6506d4","metadata":{},"source":["### Train ViT"]},{"cell_type":"code","execution_count":null,"id":"800ffbe8","metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2024-08-03T10:51:15.640783Z","iopub.status.busy":"2024-08-03T10:51:15.640426Z","iopub.status.idle":"2024-08-03T13:01:29.658021Z","shell.execute_reply":"2024-08-03T13:01:29.657032Z","shell.execute_reply.started":"2024-08-03T10:51:15.640755Z"},"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[],"source":["from torch.optim.lr_scheduler import StepLR, CosineAnnealingLR\n","import torch.optim as optim\n","\n","# build models\n","model = ViT(\n","    image_size = 32,\n","    patch_size = 4,\n","    num_classes = 10,\n","    dim = 64,\n","    depth = 6,\n","    heads= 8,\n","    mlp_dim = 512,\n","    dropout = 0.1,\n","    emb_dropout = 0.1, \n",")\n","\n","# loss function\n","loss_function = nn.CrossEntropyLoss()\n","\n","# optimizer\n","lr = 1e-3\n","weight_decay = 5e-5\n","optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n","\n","# scheduler\n","gamma = 0.1\n","scheduler = StepLR(optimizer, step_size=1, gamma=gamma)\n","# scheduler = CosineAnnealingLR(optimizer, T_max=200, eta_min=1e-5)\n","\n","train(model=model,\n","      train_dataset=train_dataset,\n","      val_dataset=val_dataset,\n","      epoch=200,\n","      batch_size=32,\n","      loss_function=loss_function,\n","      optimizer=optimizer,\n","#       resume='',\n","#       start_epoch=21,\n",")"]},{"cell_type":"markdown","id":"268c0807","metadata":{},"source":["## 5. Evalution\n","\n","Except compare accurancy, we have many other metrics.\n"," "]},{"cell_type":"code","execution_count":16,"id":"e0791aad","metadata":{},"outputs":[],"source":["from sklearn.metrics import confusion_matrix\n","import plotly.figure_factory as ff\n","\n","def getConfusionMatrix(label_list, prediction_list, save_root=None):\n","        cm = confusion_matrix(label_list, prediction_list, labels=range(10), normalize=None)\n","        # Create the list of unique labels in the test set, to use in our plot\n","        x = y = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n","\n","        # Plot the matrix above as a heatmap with annotations (values) in its cells\n","        fig = ff.create_annotated_heatmap(cm, x, y)\n","        # Set titles and ordering\n","        fig.update_layout(  title_text=\"<b>Confusion matrix</b>\", \n","                            yaxis = dict(categoryorder = \"category descending\"))\n","        fig.add_annotation(dict(font=dict(color=\"black\",size=14),\n","                                x=0.5,\n","                                y=-0.15,\n","                                showarrow=False,\n","                                text=\"Predicted label\",\n","                                xref=\"paper\",\n","                                yref=\"paper\"))\n","        fig.add_annotation(dict(font=dict(color=\"black\",size=14),\n","                                x=-0.15,\n","                                y=0.5,\n","                                showarrow=False,\n","                                text=\"Actual label\",\n","                                textangle=-90,\n","                                xref=\"paper\",\n","                                yref=\"paper\"))\n","        # We need margins so the titles fit\n","        fig.update_layout(margin=dict(t=80, r=20, l=100, b=50))\n","        fig['data'][0]['showscale'] = True\n","        fig.show()\n","\n","        return cm\n","\n","\n","# import matplotlib.pyplot as plt\n","# from sklearn.metrics import roc_curve, auc, roc_auc_score, recall_score, f1_score\n","# from sklearn.utils.multiclass import type_of_target\n","# import numpy as np\n","# from sklearn.preprocessing import label_binarize\n","\n","\n","# # def getRocAuc(y_true, y_scores):\n","# #     y_one_hot = label_binarize(y_true, classes=np.arange(10))\n","# #     fpr, tpr, threshold = roc_curve(y_one_hot.ravel(), y_scores.ravel())\n","# #     roc_auc = auc(fpr, tpr)\n","# #     plt.figure()\n","# #     lw = 2\n","# #     plt.figure(figsize=(10, 10))\n","# #     plt.plot(fpr, tpr, color='darkorange', lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)  # 假正率为横坐标，真正率为纵坐标做曲线\n","# #     plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n","# #     plt.xlim([0.0, 1.0])\n","# #     plt.ylim([0.0, 1.05])\n","# #     plt.legend(loc=\"lower right\")\n","# #     plt.show()"]},{"cell_type":"code","execution_count":22,"id":"1304e1ad","metadata":{},"outputs":[{"data":{"application/vnd.plotly.v1+json":{"config":{"plotlyServerURL":"https://plot.ly"},"data":[{"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"reversescale":false,"showscale":true,"type":"heatmap","x":["airplane","automobile","bird","cat","deer","dog","frog","horse","ship","truck"],"y":["airplane","automobile","bird","cat","deer","dog","frog","horse","ship","truck"],"z":[[957,3,5,2,6,21,3,15,6,2],[8,949,15,1,2,6,4,0,2,0],[6,4,966,3,5,3,5,9,1,1],[1,0,0,929,5,0,19,2,3,11],[8,1,15,1,943,1,9,13,4,0],[45,4,17,1,6,887,1,4,2,1],[4,3,1,6,13,0,982,0,5,2],[6,0,5,0,6,4,2,1007,0,0],[2,0,0,7,2,0,7,3,983,13],[1,0,0,2,0,0,2,0,11,978]]}],"layout":{"annotations":[{"font":{"color":"#000000"},"showarrow":false,"text":"957","x":"airplane","xref":"x","y":"airplane","yref":"y"},{"font":{"color":"#FFFFFF"},"showarrow":false,"text":"3","x":"automobile","xref":"x","y":"airplane","yref":"y"},{"font":{"color":"#FFFFFF"},"showarrow":false,"text":"5","x":"bird","xref":"x","y":"airplane","yref":"y"},{"font":{"color":"#FFFFFF"},"showarrow":false,"text":"2","x":"cat","xref":"x","y":"airplane","yref":"y"},{"font":{"color":"#FFFFFF"},"showarrow":false,"text":"6","x":"deer","xref":"x","y":"airplane","yref":"y"},{"font":{"color":"#FFFFFF"},"showarrow":false,"text":"21","x":"dog","xref":"x","y":"airplane","yref":"y"},{"font":{"color":"#FFFFFF"},"showarrow":false,"text":"3","x":"frog","xref":"x","y":"airplane","yref":"y"},{"font":{"color":"#FFFFFF"},"showarrow":false,"text":"15","x":"horse","xref":"x","y":"airplane","yref":"y"},{"font":{"color":"#FFFFFF"},"showarrow":false,"text":"6","x":"ship","xref":"x","y":"airplane","yref":"y"},{"font":{"color":"#FFFFFF"},"showarrow":false,"text":"2","x":"truck","xref":"x","y":"airplane","yref":"y"},{"font":{"color":"#FFFFFF"},"showarrow":false,"text":"8","x":"airplane","xref":"x","y":"automobile","yref":"y"},{"font":{"color":"#000000"},"showarrow":false,"text":"949","x":"automobile","xref":"x","y":"automobile","yref":"y"},{"font":{"color":"#FFFFFF"},"showarrow":false,"text":"15","x":"bird","xref":"x","y":"automobile","yref":"y"},{"font":{"color":"#FFFFFF"},"showarrow":false,"text":"1","x":"cat","xref":"x","y":"automobile","yref":"y"},{"font":{"color":"#FFFFFF"},"showarrow":false,"text":"2","x":"deer","xref":"x","y":"automobile","yref":"y"},{"font":{"color":"#FFFFFF"},"showarrow":false,"text":"6","x":"dog","xref":"x","y":"automobile","yref":"y"},{"font":{"color":"#FFFFFF"},"showarrow":false,"text":"4","x":"frog","xref":"x","y":"automobile","yref":"y"},{"font":{"color":"#FFFFFF"},"showarrow":false,"text":"0","x":"horse","xref":"x","y":"automobile","yref":"y"},{"font":{"color":"#FFFFFF"},"showarrow":false,"text":"2","x":"ship","xref":"x","y":"automobile","yref":"y"},{"font":{"color":"#FFFFFF"},"showarrow":false,"text":"0","x":"truck","xref":"x","y":"automobile","yref":"y"},{"font":{"color":"#FFFFFF"},"showarrow":false,"text":"6","x":"airplane","xref":"x","y":"bird","yref":"y"},{"font":{"color":"#FFFFFF"},"showarrow":false,"text":"4","x":"automobile","xref":"x","y":"bird","yref":"y"},{"font":{"color":"#000000"},"showarrow":false,"text":"966","x":"bird","xref":"x","y":"bird","yref":"y"},{"font":{"color":"#FFFFFF"},"showarrow":false,"text":"3","x":"cat","xref":"x","y":"bird","yref":"y"},{"font":{"color":"#FFFFFF"},"showarrow":false,"text":"5","x":"deer","xref":"x","y":"bird","yref":"y"},{"font":{"color":"#FFFFFF"},"showarrow":false,"text":"3","x":"dog","xref":"x","y":"bird","yref":"y"},{"font":{"color":"#FFFFFF"},"showarrow":false,"text":"5","x":"frog","xref":"x","y":"bird","yref":"y"},{"font":{"color":"#FFFFFF"},"showarrow":false,"text":"9","x":"horse","xref":"x","y":"bird","yref":"y"},{"font":{"color":"#FFFFFF"},"showarrow":false,"text":"1","x":"ship","xref":"x","y":"bird","yref":"y"},{"font":{"color":"#FFFFFF"},"showarrow":false,"text":"1","x":"truck","xref":"x","y":"bird","yref":"y"},{"font":{"color":"#FFFFFF"},"showarrow":false,"text":"1","x":"airplane","xref":"x","y":"cat","yref":"y"},{"font":{"color":"#FFFFFF"},"showarrow":false,"text":"0","x":"automobile","xref":"x","y":"cat","yref":"y"},{"font":{"color":"#FFFFFF"},"showarrow":false,"text":"0","x":"bird","xref":"x","y":"cat","yref":"y"},{"font":{"color":"#000000"},"showarrow":false,"text":"929","x":"cat","xref":"x","y":"cat","yref":"y"},{"font":{"color":"#FFFFFF"},"showarrow":false,"text":"5","x":"deer","xref":"x","y":"cat","yref":"y"},{"font":{"color":"#FFFFFF"},"showarrow":false,"text":"0","x":"dog","xref":"x","y":"cat","yref":"y"},{"font":{"color":"#FFFFFF"},"showarrow":false,"text":"19","x":"frog","xref":"x","y":"cat","yref":"y"},{"font":{"color":"#FFFFFF"},"showarrow":false,"text":"2","x":"horse","xref":"x","y":"cat","yref":"y"},{"font":{"color":"#FFFFFF"},"showarrow":false,"text":"3","x":"ship","xref":"x","y":"cat","yref":"y"},{"font":{"color":"#FFFFFF"},"showarrow":false,"text":"11","x":"truck","xref":"x","y":"cat","yref":"y"},{"font":{"color":"#FFFFFF"},"showarrow":false,"text":"8","x":"airplane","xref":"x","y":"deer","yref":"y"},{"font":{"color":"#FFFFFF"},"showarrow":false,"text":"1","x":"automobile","xref":"x","y":"deer","yref":"y"},{"font":{"color":"#FFFFFF"},"showarrow":false,"text":"15","x":"bird","xref":"x","y":"deer","yref":"y"},{"font":{"color":"#FFFFFF"},"showarrow":false,"text":"1","x":"cat","xref":"x","y":"deer","yref":"y"},{"font":{"color":"#000000"},"showarrow":false,"text":"943","x":"deer","xref":"x","y":"deer","yref":"y"},{"font":{"color":"#FFFFFF"},"showarrow":false,"text":"1","x":"dog","xref":"x","y":"deer","yref":"y"},{"font":{"color":"#FFFFFF"},"showarrow":false,"text":"9","x":"frog","xref":"x","y":"deer","yref":"y"},{"font":{"color":"#FFFFFF"},"showarrow":false,"text":"13","x":"horse","xref":"x","y":"deer","yref":"y"},{"font":{"color":"#FFFFFF"},"showarrow":false,"text":"4","x":"ship","xref":"x","y":"deer","yref":"y"},{"font":{"color":"#FFFFFF"},"showarrow":false,"text":"0","x":"truck","xref":"x","y":"deer","yref":"y"},{"font":{"color":"#FFFFFF"},"showarrow":false,"text":"45","x":"airplane","xref":"x","y":"dog","yref":"y"},{"font":{"color":"#FFFFFF"},"showarrow":false,"text":"4","x":"automobile","xref":"x","y":"dog","yref":"y"},{"font":{"color":"#FFFFFF"},"showarrow":false,"text":"17","x":"bird","xref":"x","y":"dog","yref":"y"},{"font":{"color":"#FFFFFF"},"showarrow":false,"text":"1","x":"cat","xref":"x","y":"dog","yref":"y"},{"font":{"color":"#FFFFFF"},"showarrow":false,"text":"6","x":"deer","xref":"x","y":"dog","yref":"y"},{"font":{"color":"#000000"},"showarrow":false,"text":"887","x":"dog","xref":"x","y":"dog","yref":"y"},{"font":{"color":"#FFFFFF"},"showarrow":false,"text":"1","x":"frog","xref":"x","y":"dog","yref":"y"},{"font":{"color":"#FFFFFF"},"showarrow":false,"text":"4","x":"horse","xref":"x","y":"dog","yref":"y"},{"font":{"color":"#FFFFFF"},"showarrow":false,"text":"2","x":"ship","xref":"x","y":"dog","yref":"y"},{"font":{"color":"#FFFFFF"},"showarrow":false,"text":"1","x":"truck","xref":"x","y":"dog","yref":"y"},{"font":{"color":"#FFFFFF"},"showarrow":false,"text":"4","x":"airplane","xref":"x","y":"frog","yref":"y"},{"font":{"color":"#FFFFFF"},"showarrow":false,"text":"3","x":"automobile","xref":"x","y":"frog","yref":"y"},{"font":{"color":"#FFFFFF"},"showarrow":false,"text":"1","x":"bird","xref":"x","y":"frog","yref":"y"},{"font":{"color":"#FFFFFF"},"showarrow":false,"text":"6","x":"cat","xref":"x","y":"frog","yref":"y"},{"font":{"color":"#FFFFFF"},"showarrow":false,"text":"13","x":"deer","xref":"x","y":"frog","yref":"y"},{"font":{"color":"#FFFFFF"},"showarrow":false,"text":"0","x":"dog","xref":"x","y":"frog","yref":"y"},{"font":{"color":"#000000"},"showarrow":false,"text":"982","x":"frog","xref":"x","y":"frog","yref":"y"},{"font":{"color":"#FFFFFF"},"showarrow":false,"text":"0","x":"horse","xref":"x","y":"frog","yref":"y"},{"font":{"color":"#FFFFFF"},"showarrow":false,"text":"5","x":"ship","xref":"x","y":"frog","yref":"y"},{"font":{"color":"#FFFFFF"},"showarrow":false,"text":"2","x":"truck","xref":"x","y":"frog","yref":"y"},{"font":{"color":"#FFFFFF"},"showarrow":false,"text":"6","x":"airplane","xref":"x","y":"horse","yref":"y"},{"font":{"color":"#FFFFFF"},"showarrow":false,"text":"0","x":"automobile","xref":"x","y":"horse","yref":"y"},{"font":{"color":"#FFFFFF"},"showarrow":false,"text":"5","x":"bird","xref":"x","y":"horse","yref":"y"},{"font":{"color":"#FFFFFF"},"showarrow":false,"text":"0","x":"cat","xref":"x","y":"horse","yref":"y"},{"font":{"color":"#FFFFFF"},"showarrow":false,"text":"6","x":"deer","xref":"x","y":"horse","yref":"y"},{"font":{"color":"#FFFFFF"},"showarrow":false,"text":"4","x":"dog","xref":"x","y":"horse","yref":"y"},{"font":{"color":"#FFFFFF"},"showarrow":false,"text":"2","x":"frog","xref":"x","y":"horse","yref":"y"},{"font":{"color":"#000000"},"showarrow":false,"text":"1007","x":"horse","xref":"x","y":"horse","yref":"y"},{"font":{"color":"#FFFFFF"},"showarrow":false,"text":"0","x":"ship","xref":"x","y":"horse","yref":"y"},{"font":{"color":"#FFFFFF"},"showarrow":false,"text":"0","x":"truck","xref":"x","y":"horse","yref":"y"},{"font":{"color":"#FFFFFF"},"showarrow":false,"text":"2","x":"airplane","xref":"x","y":"ship","yref":"y"},{"font":{"color":"#FFFFFF"},"showarrow":false,"text":"0","x":"automobile","xref":"x","y":"ship","yref":"y"},{"font":{"color":"#FFFFFF"},"showarrow":false,"text":"0","x":"bird","xref":"x","y":"ship","yref":"y"},{"font":{"color":"#FFFFFF"},"showarrow":false,"text":"7","x":"cat","xref":"x","y":"ship","yref":"y"},{"font":{"color":"#FFFFFF"},"showarrow":false,"text":"2","x":"deer","xref":"x","y":"ship","yref":"y"},{"font":{"color":"#FFFFFF"},"showarrow":false,"text":"0","x":"dog","xref":"x","y":"ship","yref":"y"},{"font":{"color":"#FFFFFF"},"showarrow":false,"text":"7","x":"frog","xref":"x","y":"ship","yref":"y"},{"font":{"color":"#FFFFFF"},"showarrow":false,"text":"3","x":"horse","xref":"x","y":"ship","yref":"y"},{"font":{"color":"#000000"},"showarrow":false,"text":"983","x":"ship","xref":"x","y":"ship","yref":"y"},{"font":{"color":"#FFFFFF"},"showarrow":false,"text":"13","x":"truck","xref":"x","y":"ship","yref":"y"},{"font":{"color":"#FFFFFF"},"showarrow":false,"text":"1","x":"airplane","xref":"x","y":"truck","yref":"y"},{"font":{"color":"#FFFFFF"},"showarrow":false,"text":"0","x":"automobile","xref":"x","y":"truck","yref":"y"},{"font":{"color":"#FFFFFF"},"showarrow":false,"text":"0","x":"bird","xref":"x","y":"truck","yref":"y"},{"font":{"color":"#FFFFFF"},"showarrow":false,"text":"2","x":"cat","xref":"x","y":"truck","yref":"y"},{"font":{"color":"#FFFFFF"},"showarrow":false,"text":"0","x":"deer","xref":"x","y":"truck","yref":"y"},{"font":{"color":"#FFFFFF"},"showarrow":false,"text":"0","x":"dog","xref":"x","y":"truck","yref":"y"},{"font":{"color":"#FFFFFF"},"showarrow":false,"text":"2","x":"frog","xref":"x","y":"truck","yref":"y"},{"font":{"color":"#FFFFFF"},"showarrow":false,"text":"0","x":"horse","xref":"x","y":"truck","yref":"y"},{"font":{"color":"#FFFFFF"},"showarrow":false,"text":"11","x":"ship","xref":"x","y":"truck","yref":"y"},{"font":{"color":"#000000"},"showarrow":false,"text":"978","x":"truck","xref":"x","y":"truck","yref":"y"},{"font":{"color":"black","size":14},"showarrow":false,"text":"Predicted label","x":0.5,"xref":"paper","y":-0.15,"yref":"paper"},{"font":{"color":"black","size":14},"showarrow":false,"text":"Actual label","textangle":-90,"x":-0.15,"xref":"paper","y":0.5,"yref":"paper"}],"margin":{"b":50,"l":100,"r":20,"t":80},"template":{"data":{"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"barpolar":[{"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"type":"carpet"}],"choropleth":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"choropleth"}],"contour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"contour"}],"contourcarpet":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"contourcarpet"}],"heatmap":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmap"}],"heatmapgl":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmapgl"}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"histogram2d":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2d"}],"histogram2dcontour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2dcontour"}],"mesh3d":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"mesh3d"}],"parcoords":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"parcoords"}],"pie":[{"automargin":true,"type":"pie"}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"scatter3d":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatter3d"}],"scattercarpet":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattercarpet"}],"scattergeo":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergeo"}],"scattergl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergl"}],"scattermapbox":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermapbox"}],"scatterpolar":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolar"}],"scatterpolargl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolargl"}],"scatterternary":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterternary"}],"surface":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"surface"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}]},"layout":{"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"autotypenumbers":"strict","coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]],"sequential":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"sequentialminus":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]]},"colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"geo":{"bgcolor":"white","lakecolor":"white","landcolor":"#E5ECF6","showlakes":true,"showland":true,"subunitcolor":"white"},"hoverlabel":{"align":"left"},"hovermode":"closest","mapbox":{"style":"light"},"paper_bgcolor":"white","plot_bgcolor":"#E5ECF6","polar":{"angularaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"bgcolor":"#E5ECF6","radialaxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"scene":{"xaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","gridwidth":2,"linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white"},"yaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","gridwidth":2,"linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white"},"zaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","gridwidth":2,"linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white"}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"ternary":{"aaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"baxis":{"gridcolor":"white","linecolor":"white","ticks":""},"bgcolor":"#E5ECF6","caxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"title":{"x":0.05},"xaxis":{"automargin":true,"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","zerolinewidth":2},"yaxis":{"automargin":true,"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","zerolinewidth":2}}},"title":{"text":"<b>Confusion matrix</b>"},"xaxis":{"dtick":1,"gridcolor":"rgb(0, 0, 0)","side":"top","ticks":""},"yaxis":{"categoryorder":"category descending","dtick":1,"ticks":"","ticksuffix":"  "}}}},"metadata":{},"output_type":"display_data"}],"source":["def evaluate(model,\n","         checkpoint_path,\n","         val_dataset,\n","         batch_size,\n","         device = 'cuda:0',\n","    ):\n","\n","    model.load_state_dict(torch.load(checkpoint_path))\n","    model.to(device)\n","    val_dataloader = DataLoader(dataset = val_dataset, batch_size=batch_size)\n","\n","    label_list = []\n","    prediction_list = []\n","    with torch.no_grad():\n","        val_accuracy = 0\n","        for idx, (data, label) in enumerate(val_dataloader):\n","            data = data.to(device)\n","            label = label.to(device)\n","\n","            outputs = model(data)\n","            acc = (outputs.argmax(dim=1) == label).float().mean()\n","            val_accuracy += acc / len(val_dataloader)\n","\n","            label_list += label.tolist()\n","            prediction_list += outputs.argmax(dim=1).tolist()\n","            # if idx == 0:\n","            #     prediction_scores  = outputs.cpu().numpy()\n","            # else:\n","            #     prediction_scores = np.concatenate((prediction_scores , outputs.cpu().numpy()), axis=0)\n","        # print(outputs)\n","        # print(outputs.argmax(dim=1))\n","        # print(prediction_scores.shape)\n","        # plot_roc(label_list, prediction_scores)\n","        getConfusionMatrix(label_list, prediction_list)\n","evaluate(model=resnet34(),\n","     checkpoint_path='./best_epoch_98_0.9131.pth',\n","     val_dataset=val_dataset,\n","     batch_size=32\n",")"]},{"cell_type":"code","execution_count":null,"id":"b2c4cb82","metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","id":"a3518a6c","metadata":{},"source":["## 6. Ensemble Learning"]},{"cell_type":"code","execution_count":null,"id":"5a3c5cbe","metadata":{},"outputs":[],"source":["def EnsembleLearning(model1,\n","         checkpoint_path1,\n","         model2,\n","         checkpoint_path2,\n","         test_dataset,\n","         batch_size,\n","         result_path = 'submission.csv',\n","         device = 'cuda:0',\n","    ):\n","\n","    model1.load_state_dict(torch.load(checkpoint_path1))\n","    model1.to(device)\n","    model2.load_state_dict(torch.load(checkpoint_path2))\n","    model2.to(device)\n","    test_dataloader = DataLoader(dataset = test_dataset, batch_size=batch_size)\n","    \n","    current_time = time.strftime('%Y_%m_%d_%H_%M_%S', time.localtime())\n","    output_path = os.path.join('./submissions', current_time)\n","    os.makedirs(output_path, exist_ok=True)\n","    f = open(os.path.join(output_path, result_path), 'w', encoding='utf-8')\n","    f.write('id,label\\n')\n","\n","    with torch.no_grad():\n","        for data, ids in test_dataloader:\n","            data = data.to(device)\n","            outputs = 4*model1(data) + model2(data) \n","            labels = outputs.argmax(dim=1)\n","            for i in range(len(ids)):\n","                f.write(f'{ids[i]},{labels[i]}\\n')\n","    f.close()\n","\n","model1 = resnet34()\n","model2 = ViT(\n","    image_size = 32,\n","    patch_size = 4,\n","    num_classes = 10,\n","    dim = 64,\n","    depth = 6,\n","    heads= 8,\n","    mlp_dim = 512,\n","    dropout = 0.1,\n","    emb_dropout = 0.1, \n",")\n","\n","EnsembleLearning(model1=model1,\n","     checkpoint_path1='./best_epoch_98_0.9131.pth',\n","     model2=model2,\n","     checkpoint_path2='./best_epoch_382_0.8149.pth',\n","     test_dataset=test_dataset,\n","     batch_size=32\n",")   "]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30747,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.0"}},"nbformat":4,"nbformat_minor":5}

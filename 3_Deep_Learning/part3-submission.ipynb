{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc85f3a2",
   "metadata": {},
   "source": [
    "## 0. Data downloading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0fc9e9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# # set api key\n",
    "# api_token = {\"username\":\"dd13969\",\"key\":\"\"}\n",
    "# with open('/root/.kaggle/kaggle.json', 'w') as file:\n",
    "#     json.dump(api_token, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa253f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !kaggle competitions download -c nzmsa-2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67c24640",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import zipfile\n",
    "\n",
    "# # unzip dataset\n",
    "# def unzipDataset(data_dir):\n",
    "#     zip_path = data_dir + '.zip'\n",
    "#     extract_path = os.getcwd()\n",
    "\n",
    "#     with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "#         zip_ref.extractall(extract_path)\n",
    "# file_name = 'nzmsa-2024'\n",
    "# unzipDataset(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a7a3f6",
   "metadata": {},
   "source": [
    "## 1. Data loading & preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69f427c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train dataset size: 40000, validation dataset size: 10000, test datasetsize: 5000\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import os\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# data preprocessing and augmentation\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "\n",
    "# define dataset\n",
    "class CIFAR10Dataset(Dataset):\n",
    "    \"\"\"`CIFAR10 Dataset.\n",
    "\n",
    "    Args:\n",
    "        data_list (list[str]): The images files paths of the CIFAR10 Dataset.\n",
    "        label_path (str): The path of label file.\n",
    "        transform (callable, optional): A function/transform that takes in a PIL image and returns a transformed version.\n",
    "    \"\"\"\n",
    "    def __init__(self, data_list, label_path, transform=None):\n",
    "        self.data_list = data_list\n",
    "        self.label_dict = self._csv2dict(label_path)\n",
    "        self.transform = transform\n",
    "        if self.transform is None:\n",
    "            self.transform = transforms.ToTensor()\n",
    "\n",
    "    def _csv2dict(self, label_path):\n",
    "        \"\"\"Load labels from csv file\"\"\"\n",
    "        label_dict = {}\n",
    "        with open(label_path, mode='r', encoding='utf-8') as csv_file:\n",
    "            reader = csv.DictReader(csv_file)\n",
    "            for row in reader:\n",
    "                label_dict[f'image_{row[\"id\"]}.png'] = int(row['label']) \n",
    "        return label_dict\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_list)\n",
    "     \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.data_list[idx]\n",
    "        img = Image.open(img_path)\n",
    "        img = img.convert(\"RGB\")\n",
    "        img_transformed = self.transform(img)\n",
    "        label = self.label_dict[img_path.split('/')[-1]]\n",
    "        return img_transformed, label\n",
    "\n",
    "class TestDataset(CIFAR10Dataset):\n",
    "    \"\"\"`CIFAR10 test Dataset.\n",
    "\n",
    "    Args:\n",
    "        data_list (list[str]): The images files paths of the CIFAR10 Dataset.\n",
    "        label_path (str): The path of label file.\n",
    "        transform (callable, optional): A function/transform that takes in a PIL image and returns a transformed version.\n",
    "    \"\"\"\n",
    "    \"\"\"`CIFAR10 Dataset.\n",
    "\n",
    "    Args:\n",
    "        data_list (list[str]): The images files paths of the CIFAR10 Dataset.\n",
    "        transform (callable, optional): A function/transform that takes in a PIL image and returns a transformed version.\n",
    "    \"\"\"\n",
    "    def __init__(self, data_list, transform=None):\n",
    "        self.data_list = data_list\n",
    "        self.transform = transform\n",
    "        if self.transform is None:\n",
    "            self.transform = transforms.ToTensor()\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.data_list[idx]\n",
    "        img = Image.open(img_path)\n",
    "        img = img.convert(\"RGB\")\n",
    "        img_transformed = self.transform(img)\n",
    "        id = img_path.split('_')[-1][:-4]\n",
    "        return img_transformed, id\n",
    "\n",
    "\n",
    "# load dataset\n",
    "data_root = 'cifar10_images/train'\n",
    "test_data_root = 'cifar10_images/test'\n",
    "label_path = 'train.csv'\n",
    "\n",
    "data_list = ['/'.join([data_root, i]) for i in os.listdir(data_root)]\n",
    "test_list = ['/'.join([test_data_root, i]) for i in os.listdir(test_data_root)]\n",
    "train_list, val_list = train_test_split(data_list, test_size=0.2,random_state=101)\n",
    "print(f'train dataset size: {len(train_list)}, validation dataset size: {len(val_list)}, test datasetsize: {len(test_list)}')\n",
    "\n",
    "train_dataset = CIFAR10Dataset(train_list, label_path, train_transforms)\n",
    "val_dataset = CIFAR10Dataset(val_list, label_path, val_transforms)\n",
    "test_dataset = TestDataset(test_list, test_transforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18e2a08",
   "metadata": {},
   "source": [
    "## 2. Define the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4fddd5",
   "metadata": {},
   "source": [
    "### Resnet\n",
    "[1] Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun.\n",
    "\n",
    "    Deep Residual Learning for Image Recognition\n",
    "    https://arxiv.org/abs/1512.03385v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e425523",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    \"\"\"Basic Block for resnet 18 and resnet 34\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    #BasicBlock and BottleNeck block\n",
    "    #have different output size\n",
    "    #we use class attribute expansion\n",
    "    #to distinct\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super().__init__()\n",
    "\n",
    "        #residual function\n",
    "        self.residual_function = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels * BasicBlock.expansion, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels * BasicBlock.expansion)\n",
    "        )\n",
    "\n",
    "        #shortcut\n",
    "        self.shortcut = nn.Sequential()\n",
    "\n",
    "        #the shortcut output dimension is not the same with residual function\n",
    "        #use 1*1 convolution to match the dimension\n",
    "        if stride != 1 or in_channels != BasicBlock.expansion * out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels * BasicBlock.expansion, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels * BasicBlock.expansion)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return nn.ReLU(inplace=True)(self.residual_function(x) + self.shortcut(x))\n",
    "\n",
    "class BottleNeck(nn.Module):\n",
    "    \"\"\"Residual block for resnet over 50 layers\n",
    "\n",
    "    \"\"\"\n",
    "    expansion = 4\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super().__init__()\n",
    "        self.residual_function = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, stride=stride, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels * BottleNeck.expansion, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels * BottleNeck.expansion),\n",
    "        )\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "\n",
    "        if stride != 1 or in_channels != out_channels * BottleNeck.expansion:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels * BottleNeck.expansion, stride=stride, kernel_size=1, bias=False),\n",
    "                nn.BatchNorm2d(out_channels * BottleNeck.expansion)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return nn.ReLU(inplace=True)(self.residual_function(x) + self.shortcut(x))\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, num_block, num_classes=10):\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_channels = 64\n",
    "\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True))\n",
    "        #we use a different inputsize than the original paper\n",
    "        #so conv2_x's stride is 1\n",
    "        self.conv2_x = self._make_layer(block, 64, num_block[0], 1)\n",
    "        self.conv3_x = self._make_layer(block, 128, num_block[1], 2)\n",
    "        self.conv4_x = self._make_layer(block, 256, num_block[2], 2)\n",
    "        self.conv5_x = self._make_layer(block, 512, num_block[3], 2)\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, out_channels, num_blocks, stride):\n",
    "        \"\"\"make resnet layers(by layer i didnt mean this 'layer' was the\n",
    "        same as a neuron netowork layer, ex. conv layer), one layer may\n",
    "        contain more than one residual block\n",
    "\n",
    "        Args:\n",
    "            block: block type, basic block or bottle neck block\n",
    "            out_channels: output depth channel number of this layer\n",
    "            num_blocks: how many blocks per layer\n",
    "            stride: the stride of the first block of this layer\n",
    "\n",
    "        Return:\n",
    "            return a resnet layer\n",
    "        \"\"\"\n",
    "\n",
    "        # we have num_block blocks per layer, the first block\n",
    "        # could be 1 or 2, other blocks would always be 1\n",
    "        strides = [stride] + [1] * (num_blocks - 1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_channels, out_channels, stride))\n",
    "            self.in_channels = out_channels * block.expansion\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.conv1(x)\n",
    "        output = self.conv2_x(output)\n",
    "        output = self.conv3_x(output)\n",
    "        output = self.conv4_x(output)\n",
    "        output = self.conv5_x(output)\n",
    "        output = self.avg_pool(output)\n",
    "        output = output.view(output.size(0), -1)\n",
    "        output = self.fc(output)\n",
    "\n",
    "        return output\n",
    "\n",
    "def resnet18():\n",
    "    return ResNet(BasicBlock, [2, 2, 2, 2])\n",
    "\n",
    "def resnet34():\n",
    "    return ResNet(BasicBlock, [3, 4, 6, 3])\n",
    "\n",
    "def resnet50():\n",
    "    return ResNet(BottleNeck, [3, 4, 6, 3])\n",
    "\n",
    "def resnet101():\n",
    "    return ResNet(BottleNeck, [3, 4, 23, 3])\n",
    "\n",
    "def resnet152():\n",
    "    return ResNet(BottleNeck, [3, 8, 36, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f262e3",
   "metadata": {},
   "source": [
    "### VIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a265143e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from einops import rearrange, repeat\n",
    "from einops.layers.torch import Rearrange\n",
    "\n",
    "# helpers\n",
    "\n",
    "def pair(t):\n",
    "    return t if isinstance(t, tuple) else (t, t)\n",
    "\n",
    "# classes\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, dim, hidden_dim, dropout = 0.):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.LayerNorm(dim),\n",
    "            nn.Linear(dim, hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, dim),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, dim, heads = 8, dim_head = 64, dropout = 0.):\n",
    "        super().__init__()\n",
    "        inner_dim = dim_head *  heads\n",
    "        project_out = not (heads == 1 and dim_head == dim)\n",
    "\n",
    "        self.heads = heads\n",
    "        self.scale = dim_head ** -0.5\n",
    "\n",
    "        self.norm = nn.LayerNorm(dim)\n",
    "\n",
    "        self.attend = nn.Softmax(dim = -1)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        self.to_qkv = nn.Linear(dim, inner_dim * 3, bias = False)\n",
    "\n",
    "        self.to_out = nn.Sequential(\n",
    "            nn.Linear(inner_dim, dim),\n",
    "            nn.Dropout(dropout)\n",
    "        ) if project_out else nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.norm(x)\n",
    "\n",
    "        qkv = self.to_qkv(x).chunk(3, dim = -1)\n",
    "        q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> b h n d', h = self.heads), qkv)\n",
    "\n",
    "        dots = torch.matmul(q, k.transpose(-1, -2)) * self.scale\n",
    "\n",
    "        attn = self.attend(dots)\n",
    "        attn = self.dropout(attn)\n",
    "\n",
    "        out = torch.matmul(attn, v)\n",
    "        out = rearrange(out, 'b h n d -> b n (h d)')\n",
    "        return self.to_out(out)\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, dim, depth, heads, dim_head, mlp_dim, dropout = 0.):\n",
    "        super().__init__()\n",
    "        self.norm = nn.LayerNorm(dim)\n",
    "        self.layers = nn.ModuleList([])\n",
    "        for _ in range(depth):\n",
    "            self.layers.append(nn.ModuleList([\n",
    "                Attention(dim, heads = heads, dim_head = dim_head, dropout = dropout),\n",
    "                FeedForward(dim, mlp_dim, dropout = dropout)\n",
    "            ]))\n",
    "\n",
    "    def forward(self, x):\n",
    "        for attn, ff in self.layers:\n",
    "            x = attn(x) + x\n",
    "            x = ff(x) + x\n",
    "\n",
    "        return self.norm(x)\n",
    "\n",
    "class ViT(nn.Module):\n",
    "    def __init__(self, *, image_size, patch_size, num_classes, dim, depth, heads, mlp_dim, pool = 'cls', channels = 3, dim_head = 64, dropout = 0., emb_dropout = 0.):\n",
    "        super().__init__()\n",
    "        image_height, image_width = pair(image_size)\n",
    "        patch_height, patch_width = pair(patch_size)\n",
    "\n",
    "        assert image_height % patch_height == 0 and image_width % patch_width == 0, 'Image dimensions must be divisible by the patch size.'\n",
    "\n",
    "        num_patches = (image_height // patch_height) * (image_width // patch_width)\n",
    "        patch_dim = channels * patch_height * patch_width\n",
    "        assert pool in {'cls', 'mean'}, 'pool type must be either cls (cls token) or mean (mean pooling)'\n",
    "\n",
    "        self.to_patch_embedding = nn.Sequential(\n",
    "            Rearrange('b c (h p1) (w p2) -> b (h w) (p1 p2 c)', p1 = patch_height, p2 = patch_width),\n",
    "            nn.LayerNorm(patch_dim),\n",
    "            nn.Linear(patch_dim, dim),\n",
    "            nn.LayerNorm(dim),\n",
    "        )\n",
    "\n",
    "        self.pos_embedding = nn.Parameter(torch.randn(1, num_patches + 1, dim))\n",
    "        self.cls_token = nn.Parameter(torch.randn(1, 1, dim))\n",
    "        self.dropout = nn.Dropout(emb_dropout)\n",
    "\n",
    "        self.transformer = Transformer(dim, depth, heads, dim_head, mlp_dim, dropout)\n",
    "\n",
    "        self.pool = pool\n",
    "        self.to_latent = nn.Identity()\n",
    "\n",
    "        self.mlp_head = nn.Linear(dim, num_classes)\n",
    "\n",
    "    def forward(self, img):\n",
    "        x = self.to_patch_embedding(img)\n",
    "        b, n, _ = x.shape\n",
    "\n",
    "        cls_tokens = repeat(self.cls_token, '1 1 d -> b 1 d', b = b)\n",
    "        x = torch.cat((cls_tokens, x), dim=1)\n",
    "        x += self.pos_embedding[:, :(n + 1)]\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.transformer(x)\n",
    "\n",
    "        x = x.mean(dim = 1) if self.pool == 'mean' else x[:, 0]\n",
    "\n",
    "        x = self.to_latent(x)\n",
    "        return self.mlp_head(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d06ef4",
   "metadata": {},
   "source": [
    "## 3. Metrics & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84ef251d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import plotly.figure_factory as ff\n",
    "\n",
    "def getConfusionMatrix(label_list, prediction_list, save_root=None):\n",
    "        cm = confusion_matrix(label_list, prediction_list, labels=range(10), normalize=None)\n",
    "        # We use plotly to create plots and charts\n",
    "        \n",
    "\n",
    "        # Create the list of unique labels in the test set, to use in our plot\n",
    "        # I.e., ['animal', 'hiker', 'rock', 'tree']\n",
    "        x = y = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "        # Plot the matrix above as a heatmap with annotations (values) in its cells\n",
    "        fig = ff.create_annotated_heatmap(cm, x, y)\n",
    "        # Set titles and ordering\n",
    "        fig.update_layout(  title_text=\"<b>Confusion matrix</b>\", \n",
    "                            yaxis = dict(categoryorder = \"category descending\"))\n",
    "        fig.add_annotation(dict(font=dict(color=\"black\",size=14),\n",
    "                                x=0.5,\n",
    "                                y=-0.15,\n",
    "                                showarrow=False,\n",
    "                                text=\"Predicted label\",\n",
    "                                xref=\"paper\",\n",
    "                                yref=\"paper\"))\n",
    "        fig.add_annotation(dict(font=dict(color=\"black\",size=14),\n",
    "                                x=-0.15,\n",
    "                                y=0.5,\n",
    "                                showarrow=False,\n",
    "                                text=\"Actual label\",\n",
    "                                textangle=-90,\n",
    "                                xref=\"paper\",\n",
    "                                yref=\"paper\"))\n",
    "        # We need margins so the titles fit\n",
    "        fig.update_layout(margin=dict(t=80, r=20, l=100, b=50))\n",
    "        fig['data'][0]['showscale'] = True\n",
    "        fig.show() \n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score, recall_score, f1_score\n",
    "from sklearn.utils.multiclass import type_of_target\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "\n",
    "def plot_loss(loss_list):\n",
    "    plt.figure('PyTorch_CNN_Loss')\n",
    "    plt.plot(loss_list, label='Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_acc(acc_list):\n",
    "    plt.figure('PyTorch_CNN_Acc')\n",
    "    plt.plot(acc_list, label='Acc')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_roc(y_true, y_scores):\n",
    "    # y_true = y_true.numpy()\n",
    "    # y_scores = y_scores.numpy()\n",
    "\n",
    "    y_one_hot = label_binarize(y_true, classes=np.arange(10))\n",
    "\n",
    "    # print(type(predicted))\n",
    "    # y_scores = np.amax(y_true, axis=1)\n",
    "    # print(type_of_target((y_true)))\n",
    "    # print(type_of_target(y_scores))\n",
    "    # exit()\n",
    "    print(len(y_true))\n",
    "    # print(y_true.shape)  # (157,)\n",
    "    print(y_scores.shape)  # (157, 10)\n",
    "    print(y_one_hot.shape)  # (157, 7)\n",
    "    # exit()\n",
    "\n",
    "    fpr, tpr, threshold = roc_curve(y_one_hot.ravel(), y_scores.ravel())\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.figure()\n",
    "    lw = 2\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)  # 假正率为横坐标，真正率为纵坐标做曲线\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea88b5d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "774aa93e",
   "metadata": {},
   "source": [
    "## 4. Train & Test pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7c7408",
   "metadata": {},
   "source": [
    "### train pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d42b7030",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "# from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import roc_curve\n",
    "def train(model,\n",
    "          train_dataset,\n",
    "          val_dataset,\n",
    "          batch_size,\n",
    "          epoch,\n",
    "          loss_function,\n",
    "          optimizer,\n",
    "          output_root = './outputs',\n",
    "          save_epoch = 1,\n",
    "          resume = None,\n",
    "          start_epoch = 1,\n",
    "    ):\n",
    "    device = 'cuda:0'\n",
    "    best_acc = 0\n",
    "    if resume:\n",
    "        model.load_state_dict(torch.load(resume))\n",
    "        model.to(device)\n",
    "\n",
    "    current_time = time.strftime('%Y_%m_%d_%H_%M_%S', time.localtime())\n",
    "    output_path = os.path.join(output_root, current_time)\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    train_dataloader = DataLoader(dataset = train_dataset, batch_size=batch_size, shuffle=True )\n",
    "    val_dataloader = DataLoader(dataset = val_dataset, batch_size=batch_size, shuffle=True)\n",
    "    iter_num =  len(train_dataset) / train_dataloader.batch_size\n",
    "    f_log = open(os.path.join(output_path, 'loss.log'), 'w', encoding='utf-8')\n",
    "    f_loss_acc = open(os.path.join(output_path, 'loss.log'), 'w', encoding='utf-8')\n",
    "    for e in range(start_epoch, epoch+1):\n",
    "        train_loss = 0\n",
    "        train_accuracy = 0\n",
    "        \n",
    "        for idx, (data, label) in enumerate(train_dataloader):\n",
    "            data, label = data.to(device), label.to(device)\n",
    "\n",
    "            outputs = model(data)\n",
    "            loss = loss_function(outputs, label)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            acc = (outputs.argmax(dim=1) == label).float().mean()\n",
    "            train_accuracy += acc / len(train_dataloader)\n",
    "            train_loss += loss / len(train_dataloader)\n",
    "\n",
    "            if idx % 1000 == 0:\n",
    "                print(f'Epoch:{e}/{epoch}, iter:{idx}/{iter_num}, loss:{loss.item():.4f}')\n",
    "\n",
    "            f_loss_acc.write(f'{loss.item():.4f}\\n')\n",
    "\n",
    "\n",
    "        label_list = []\n",
    "        prediction_list = []\n",
    "        with torch.no_grad():\n",
    "            val_accuracy = 0\n",
    "            val_loss = 0\n",
    "            for idx, (data, label) in enumerate(val_dataloader):\n",
    "                data = data.to(device)\n",
    "                label = label.to(device)\n",
    "\n",
    "                outputs = model(data)\n",
    "                loss = loss_function(outputs, label)\n",
    "                acc = (outputs.argmax(dim=1) == label).float().mean()\n",
    "                val_accuracy += acc / len(val_dataloader)\n",
    "                val_loss += loss / len(val_dataloader)\n",
    "\n",
    "                label_list += label.tolist()\n",
    "                prediction_list += outputs.argmax(dim=1).tolist()\n",
    "                if idx == 0:\n",
    "                    prediction_scores  = outputs.cpu().numpy()\n",
    "                else:\n",
    "                    prediction_scores = np.concatenate((prediction_scores , outputs.cpu().numpy()), axis=0)\n",
    "        # print(outputs)\n",
    "        # print(outputs.argmax(dim=1))\n",
    "        # print(prediction_scores.shape)\n",
    "        # plot_roc(label_list, prediction_scores)\n",
    "        # getConfusionMatrix(label_list, prediction_list)\n",
    "        print(f'Epoch:{e}/{epoch}, train_loss:{train_loss:.4f}, train_accuracy:{train_accuracy:.4f}, val_loss:{val_loss:.4f}, val_accuracy:{val_accuracy:.4f}')\n",
    "        f_log.write(f'Epoch:{e}/{epoch}, train_loss:{train_loss:.4f}, train_accuracy:{train_accuracy:.4f}, val_loss:{val_loss:.4f}, val_accuracy:{val_accuracy:.4f}\\n')\n",
    "        \n",
    "        # model saving\n",
    "        #start to save best performance model after learning rate decay to 0.01\n",
    "        if best_acc < val_accuracy:\n",
    "            model_name = f'best_epoch_{e}_{val_accuracy:.4f}.pth'\n",
    "            save_path = os.path.join(output_path, model_name)\n",
    "            print(f'saving best model to {save_path}')\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            best_acc = val_accuracy\n",
    "            continue\n",
    "\n",
    "        if epoch % save_epoch == 0:\n",
    "            model_name = f'epoch_{e}_{val_accuracy:.4f}.pth'\n",
    "            save_path = os.path.join(output_path, model_name)\n",
    "            print(f'saving model to {save_path}')\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "    \n",
    "    \n",
    "    f_loss_acc.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86c5c5c",
   "metadata": {},
   "source": [
    "### test pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332642db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model,\n",
    "         checkpoint_path,\n",
    "         test_dataset,\n",
    "         batch_size,\n",
    "         result_path = 'submission.csv',\n",
    "         device = 'cuda:0',\n",
    "    ):\n",
    "\n",
    "    model.load_state_dict(torch.load(checkpoint_path))\n",
    "    model.to(device)\n",
    "    test_dataloader = DataLoader(dataset = test_dataset, batch_size=batch_size)\n",
    "    \n",
    "    current_time = time.strftime('%Y_%m_%d_%H_%M_%S', time.localtime())\n",
    "    output_path = os.path.join('./submissions', current_time)\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    f = open(os.path.join(output_path, result_path), 'w', encoding='utf-8')\n",
    "    f.write('id,label\\n')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, ids in test_dataloader:\n",
    "            data = data.to(device)\n",
    "\n",
    "            outputs = model(data)\n",
    "            labels = outputs.argmax(dim=1)\n",
    "            for i in range(len(ids)):\n",
    "                f.write(f'{ids[i]},{labels[i]}\\n')\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142c8e84",
   "metadata": {},
   "source": [
    "## 5. Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56bf9a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import StepLR\n",
    "import torch.optim as optim\n",
    "# from linformer import Linformer\n",
    "\n",
    "# loss function\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "# optimizer\n",
    "lr = 3e-5\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "# scheduler\n",
    "gamma = 0.7\n",
    "scheduler = StepLR(optimizer, step_size=1, gamma=gamma)\n",
    "\n",
    "model = resnet50().to('cuda:0')\n",
    "\n",
    "train(model=model,\n",
    "      train_dataset=train_dataset,\n",
    "      val_dataset=val_dataset,\n",
    "      epoch=100,\n",
    "      batch_size=8,\n",
    "      loss_function=loss_function,\n",
    "      optimizer=optimizer,\n",
    "      # resume='outputs/2024_07_27_17_59_17/epoch_10_0.6693.pth',\n",
    "      # start_epoch=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1f4455a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet50().to('cuda:0')\n",
    "test(model=model,\n",
    "     checkpoint_path='./outputs/2024_07_31_02_53_18/best_epoch_17_0.7836.pth',\n",
    "     test_dataset=test_dataset,\n",
    "     batch_size=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31a44c67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
